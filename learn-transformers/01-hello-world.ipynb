{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4ef98138-f7ee-430b-9cce-03cf8898c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers as L\n",
    "from keras import models as M\n",
    "from keras import losses as LL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d18bee-0901-48b1-816c-941873f8e5dc",
   "metadata": {},
   "source": [
    "# Hello world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f632c52-8443-4aeb-a6a1-872182fe383b",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed1f6d0-b3af-49f7-8873-69b353c8005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64dbf06a-f7df-483c-a9c7-d1f3e9a49825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9997972846031189}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this movie was bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70fe95e2-7e3f-4988-9104-247376524314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9997695088386536}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"It wasn't as good ad the previous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e1b49c-baf0-4fbd-bf23-5f201f71fa64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9938271641731262}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"The enjoyment I got from the evening was just that from the 1lb popcon I got at the theater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a1ad45-bed2-4ff2-a61d-8193818545c0",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da2b020-62ec-4402-b4f7-f1cce503606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"ner\", aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cb84cb6-ec71-435f-a555-b1abaadef08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999712</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.966197</td>\n",
       "      <td>Ahn Duk</td>\n",
       "      <td>68</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.608237</td>\n",
       "      <td>geun</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>European Union</td>\n",
       "      <td>177</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>America</td>\n",
       "      <td>229</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>Japan</td>\n",
       "      <td>276</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>Korea</td>\n",
       "      <td>283</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>China</td>\n",
       "      <td>290</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score            word  start  end\n",
       "0          LOC  0.999712     South Korea     53   64\n",
       "1          PER  0.966197         Ahn Duk     68   75\n",
       "2          PER  0.608237            geun     76   80\n",
       "3          ORG  0.999320  European Union    177  191\n",
       "4          LOC  0.999527         America    229  236\n",
       "5          LOC  0.999736           Japan    276  281\n",
       "6          LOC  0.999751           Korea    283  288\n",
       "7          LOC  0.999734           China    290  295"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Trade ministers are not known for histrionics. \n",
    "Yet South Korea’s, Ahn Duk-geun, is alarmed. \n",
    "The world is on the verge of opening Pandora’s box, he warned last month. \n",
    "If the European Union follows through on threats \n",
    "to mimic America’s protectionist industrial policies, \n",
    "“Japan, Korea, China, every country will engage in this very difficult race \n",
    "to ignore global trading rules.”\n",
    "\"\"\"\n",
    "output = classifier(text)\n",
    "pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d5c134-6c33-4543-8f13-b05a47c51bdf",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f59d408-ef15-4b2f-88fe-fb44044e1631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--emotion-115c273ec307f160\n",
      "Reusing dataset json (/home/calcifer/.cache/huggingface/datasets/SetFit___json/SetFit--emotion-115c273ec307f160/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ca6922059847c88ce5f4a8825fea60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"SetFit/emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b86e07e-bbf3-41fe-8998-e6d7d8823d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_text'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_text'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_text'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "483b225e-ef6b-4cd1-befc-f34985bee28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated', 'label': 0, 'label_text': 'sadness'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c3792a-1670-4a8c-8159-91cec7606586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_text\n",
       "0                            i didnt feel humiliated      0    sadness\n",
       "1  i can go from feeling so hopeless to so damned...      0    sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong      3      anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      2       love\n",
       "4                               i am feeling grouchy      3      anger"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.set_format(\"pandas\")\n",
    "df = ds[\"train\"][:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b53090ef-42d9-4922-811a-c60409974144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"label_text\"].value_counts(normalize=True, ascending=True).plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1bbc164-9d0c-43bd-81c2-fb81d993d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4348033-07ad-496a-b789-ea06f56d1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d280863c-0f1f-47b6-888b-965269ac80be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102], [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2572, 2412, 3110, 16839, 9080, 12863, 2055, 1996, 13788, 1045, 2097, 2113, 2008, 2009, 2003, 2145, 2006, 1996, 3200, 102, 0], [101, 1045, 2572, 3110, 24665, 7140, 11714, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    return tokenizer(x[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "tokenize(ds[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "18674db4-0fb9-47dc-9376-78f75f0d639f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b759cb9119ae4fe6aab701412c73a44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/calcifer/.cache/huggingface/datasets/SetFit___json/SetFit--emotion-115c273ec307f160/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-446f7afe224190b3.arrow\n",
      "Loading cached processed dataset at /home/calcifer/.cache/huggingface/datasets/SetFit___json/SetFit--emotion-115c273ec307f160/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-0ff91b06df772e67.arrow\n"
     ]
    }
   ],
   "source": [
    "ds_tkn = ds.map(\n",
    "    function=tokenize,\n",
    "    batched=True,\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d7b8c83c-8e2d-4261-acb5-1e5f2ec8bb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 6\n",
    "model = (\n",
    "    AutoModelForSequenceClassification\n",
    "    .from_pretrained(model_name, num_labels=num_labels)\n",
    "    .to(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e74cc4f8-69fe-40b3-90ea-17b1cbdcb386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "63373433-4b09-4205-afd3-0537149c2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "logging_steps = len(ds_tkn[\"train\"]) // batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-emotion\",\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=False,\n",
    "    log_level=\"error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "29bc9b97-a306-49b0-84d3-324152218c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  5/500 00:16 < 45:32, 0.18 it/s, Epoch 0.02/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [153]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/transformers/trainer.py:1527\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1524\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1526\u001b[0m )\n\u001b[0;32m-> 1527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/transformers/trainer.py:1775\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1773\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1778\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1780\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/transformers/trainer.py:2541\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2539\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[1;32m   2540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2541\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=ds_tkn[\"train\"],\n",
    "    eval_dataset=ds_tkn[\"validation\"],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d26edb-908b-4e28-ab6a-be6df9c872ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710a90b-bb34-4325-8268-2ad2d53cf0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e403c8-5b4d-4ca9-a5fb-58be1aef0a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7a3a4-0693-445d-a42f-d86dfdaf652e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3faeabc-20c4-4b50-b2b4-8aa5d08724a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f4537b-5975-4485-8d34-94a6891e8ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514ae48-695f-49e2-bd3e-7a0acd922556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8656dda-c3f5-439b-a82d-93e0766b7cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae58519-1d4d-4020-8236-dc5a05e26066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4a2953e0-5be8-4089-980b-6261743f145b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "transformer = TFAutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4525f014-c12b-41f1-a50e-595e6f165571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.keys()=dict_keys(['input_ids', 'attention_mask'])\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "out.keys() = odict_keys(['last_hidden_state'])\n",
      "out['last_hidden_state'][:, 0, :].shape = (1, 768)\n"
     ]
    }
   ],
   "source": [
    "x = tokenizer(ds_tkn[\"train\"][0][\"text\"], return_tensors=\"tf\")\n",
    "print(f\"{x.keys()=}\")\n",
    "\n",
    "x[\"input_ids\"].shape\n",
    "\n",
    "out = transformer.predict(x=(x[\"input_ids\"], x[\"attention_mask\"]))\n",
    "# alternatives\n",
    "# out = transformer.predict(x={\"input_ids\": x[\"input_ids\"], \"attention_mask\":x[\"attention_mask\"]})\n",
    "# transformer(x)\n",
    "\n",
    "print(f\"{out.keys() = }\")\n",
    "print(f\"{out['last_hidden_state'][:, 0, :].shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "795cb6ee-086b-42fc-bc4f-9223b9fa7828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "873f459a-c5b6-40b0-a730-6dd0095f2d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf_distil_bert_model_1 (TFDist  TFBaseModelOutput(l  66362880   ['input_ids[0][0]',              \n",
      " ilBertModel)                   ast_hidden_state=(N               'attention_mask[0][0]']         \n",
      "                                one, None, 768),                                                  \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_distil_bert_model_1[11][0]']\n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            65          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66,412,161\n",
      "Trainable params: 66,412,161\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ids = L.Input(shape=(None, ), dtype=tf.int32, name=\"input_ids\")\n",
    "attention_mask = L.Input(shape=(None, ), dtype=tf.int32, name=\"attention_mask\")\n",
    "embeddings = transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "x = L.Dense(units=64, activation=\"relu\")(embeddings[\"last_hidden_state\"][0])\n",
    "x = L.Dense(units=1, activation=\"softmax\")(x)\n",
    "model = M.Model(inputs=[input_ids, attention_mask], outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "36653d35-618a-42b2-a646-519c0c971957",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tkn.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ca0353c7-5a86-458c-b804-f1f64038af84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585cb938701b4906948620e598e7ca29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8313cac577324a1c85960f04c78ece59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277ae091bcff4f0c85bc9cbbb5753559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feca1e70b1c6403f995715f11fa3a780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae722cff7c6405e86f941adbccc4800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09386236a32b4dda96450e68fed7fd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_tkn_y = ds_tkn.map(lambda x: {\"label\": x[\"label\"]}, batch_size=64, batched=True)\n",
    "ds_tkn_x = ds_tkn.map(lambda x: {\"input_ids\": x[\"input_ids\"], \"attention_mask\": x[\"attention_mask\"]}, batch_size=64, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b34ff778-209a-42a9-bc19-20e4ebca4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tkn.set_format(\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4f8fb42b-eab9-4447-a3f3-a544ac56d331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_tkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "60a84189-0e40-4e15-9af0-7f74458639ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tkn_train_x = ds_tkn.remove_columns([\"text\", \"label\", \"label_text\"])[\"train\"][:]\n",
    "ds_tkn_train_y = ds_tkn.remove_columns([\"text\", \"input_ids\", \"attention_mask\", \"label_text\"])[\"train\"][:]\n",
    "\n",
    "ds_tkn_val_x = ds_tkn.remove_columns([\"text\", \"label\", \"label_text\"])[\"validation\"][:]\n",
    "ds_tkn_val_y = ds_tkn.remove_columns([\"text\", \"input_ids\", \"attention_mask\", \"label_text\"])[\"validation\"][:]\n",
    "\n",
    "ds_tkn_test_x = ds_tkn.remove_columns([\"text\", \"label\", \"label_text\"])[\"test\"][:]\n",
    "ds_tkn_test_y = ds_tkn.remove_columns([\"text\", \"input_ids\", \"attention_mask\", \"label_text\"])[\"test\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f529955a-67d6-480d-b81c-8a11349eacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ds_train = tf.data.Dataset.from_tensor_slices((ds_tkn_train_x, ds_tkn_train_y,))\n",
    "tf_ds_valid = tf.data.Dataset.from_tensor_slices((ds_tkn_val_x, ds_tkn_val_y,))\n",
    "tf_ds_test = tf.data.Dataset.from_tensor_slices((ds_tkn_test_x, ds_tkn_test_y,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ef837935-de64-41bf-b562-c128441996bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER = 1000\n",
    "\n",
    "tf_ds_train_prep = tf_ds_train.batch(BATCH_SIZE).shuffle(buffer_size=BUFFER)\n",
    "tf_ds_valid_prep = tf_ds_valid.batch(BATCH_SIZE)\n",
    "tf_ds_test_prep = tf_ds_test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a281819a-52f4-46d0-a2ac-6a20ee3f3287",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filek5j84r24.py\", line 33, in tf__run_call_with_unpacked_inputs\n        unpacked_inputs = ag__.converted_call(ag__.ld(input_processing), (ag__.ld(func), ag__.ld(config)), dict(**ag__.ld(fn_args_and_kwargs)), fscope)\n    File \"/tmp/__autograph_generated_filezvqrc3gs.py\", line 138, in tf__input_processing\n        ag__.for_stmt(ag__.converted_call(ag__.ld(kwargs).items, (), None, fscope), None, loop_body, get_state_7, set_state_7, (), {'iterate_names': '(k, v)'})\n    File \"/tmp/__autograph_generated_filezvqrc3gs.py\", line 135, in loop_body\n        ag__.if_stmt(ag__.or_(lambda : ag__.converted_call(ag__.ld(isinstance), (ag__.ld(v), ag__.ld(allowed_types)), None, fscope), lambda : ag__.ld(v) is None), if_body_6, else_body_6, get_state_6, set_state_6, ('output[k]',), 1)\n    File \"/tmp/__autograph_generated_filezvqrc3gs.py\", line 134, in else_body_6\n        raise ag__.converted_call(ag__.ld(ValueError), (f'Data of type {ag__.converted_call(ag__.ld(type), (ag__.ld(v),), None, fscope)} is not allowed only {ag__.ld(allowed_types)} is accepted for {ag__.ld(k)}.',), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'tf_distil_bert_model_1' (type TFDistilBertModel).\n    \n    in user code:\n    \n        File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 558, in run_call_with_unpacked_inputs  *\n            unpacked_inputs = input_processing(func, config, **fn_args_and_kwargs)\n        File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 508, in input_processing  *\n            raise ValueError(f\"Data of type {type(v)} is not allowed only {allowed_types} is accepted for {k}.\")\n    \n        ValueError: Data of type <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'> is not allowed only (<class 'tensorflow.python.framework.ops.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>, <class 'keras.engine.keras_tensor.KerasTensor'>) is accepted for attention_mask.\n    \n    \n    Call arguments received by layer 'tf_distil_bert_model_1' (type TFDistilBertModel):\n      • self=tf.RaggedTensor(values=Tensor(\"RaggedFromVariant_1/RaggedTensorFromVariant:1\", shape=(None,), dtype=int32), row_splits=Tensor(\"RaggedFromVariant_1/RaggedTensorFromVariant:0\", shape=(None,), dtype=int32))\n      • input_ids=None\n      • attention_mask=tf.RaggedTensor(values=Tensor(\"model_10/Cast:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(None,), dtype=int32))\n      • head_mask=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • training=False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [141]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_ds_test_prep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filecroees0c.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filek5j84r24.py:33\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m config \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEncoderDecoder\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_processing\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn_args_and_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filezvqrc3gs.py:138\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__input_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m k \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    137\u001b[0m v \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m(k, v)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_19\u001b[39m():\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (ag__\u001b[38;5;241m.\u001b[39mldu(\u001b[38;5;28;01mlambda\u001b[39;00m : output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mldu(\u001b[38;5;28;01mlambda\u001b[39;00m : output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mldu(\u001b[38;5;28;01mlambda\u001b[39;00m : output[main_input_name], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput[main_input_name]\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filezvqrc3gs.py:135\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__input_processing.<locals>.loop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body_6\u001b[39m():\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;167;01mValueError\u001b[39;00m), (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mtype\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(v),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(allowed_types)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(k)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m--> 135\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mor_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mallowed_types\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput[k]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filezvqrc3gs.py:134\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__input_processing.<locals>.loop_body.<locals>.else_body_6\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body_6\u001b[39m():\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;167;01mValueError\u001b[39;00m), (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mtype\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(v),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(allowed_types)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(k)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filek5j84r24.py\", line 33, in tf__run_call_with_unpacked_inputs\n        unpacked_inputs = ag__.converted_call(ag__.ld(input_processing), (ag__.ld(func), ag__.ld(config)), dict(**ag__.ld(fn_args_and_kwargs)), fscope)\n    File \"/tmp/__autograph_generated_filezvqrc3gs.py\", line 138, in tf__input_processing\n        ag__.for_stmt(ag__.converted_call(ag__.ld(kwargs).items, (), None, fscope), None, loop_body, get_state_7, set_state_7, (), {'iterate_names': '(k, v)'})\n    File \"/tmp/__autograph_generated_filezvqrc3gs.py\", line 135, in loop_body\n        ag__.if_stmt(ag__.or_(lambda : ag__.converted_call(ag__.ld(isinstance), (ag__.ld(v), ag__.ld(allowed_types)), None, fscope), lambda : ag__.ld(v) is None), if_body_6, else_body_6, get_state_6, set_state_6, ('output[k]',), 1)\n    File \"/tmp/__autograph_generated_filezvqrc3gs.py\", line 134, in else_body_6\n        raise ag__.converted_call(ag__.ld(ValueError), (f'Data of type {ag__.converted_call(ag__.ld(type), (ag__.ld(v),), None, fscope)} is not allowed only {ag__.ld(allowed_types)} is accepted for {ag__.ld(k)}.',), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'tf_distil_bert_model_1' (type TFDistilBertModel).\n    \n    in user code:\n    \n        File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 558, in run_call_with_unpacked_inputs  *\n            unpacked_inputs = input_processing(func, config, **fn_args_and_kwargs)\n        File \"/home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 508, in input_processing  *\n            raise ValueError(f\"Data of type {type(v)} is not allowed only {allowed_types} is accepted for {k}.\")\n    \n        ValueError: Data of type <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'> is not allowed only (<class 'tensorflow.python.framework.ops.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>, <class 'keras.engine.keras_tensor.KerasTensor'>) is accepted for attention_mask.\n    \n    \n    Call arguments received by layer 'tf_distil_bert_model_1' (type TFDistilBertModel):\n      • self=tf.RaggedTensor(values=Tensor(\"RaggedFromVariant_1/RaggedTensorFromVariant:1\", shape=(None,), dtype=int32), row_splits=Tensor(\"RaggedFromVariant_1/RaggedTensorFromVariant:0\", shape=(None,), dtype=int32))\n      • input_ids=None\n      • attention_mask=tf.RaggedTensor(values=Tensor(\"model_10/Cast:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(None,), dtype=int32))\n      • head_mask=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • training=False\n"
     ]
    }
   ],
   "source": [
    "model.predict(tf_ds_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8d3cac37-2120-4afa-878d-fa87494b1b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=LL.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af9ca25-8e3e-4c69-9dcb-79b7b63867b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    tf_ds_train\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
