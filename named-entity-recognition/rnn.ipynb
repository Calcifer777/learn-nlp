{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2078da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 22:54:50.313257: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-29 22:54:50.446175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-29 22:54:50.446209: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-29 22:54:51.241356: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-29 22:54:51.241435: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-29 22:54:51.241445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    TimeDistributed,\n",
    "    Dense,\n",
    "    GRU,\n",
    "    Embedding,\n",
    "    TextVectorization,\n",
    "    Input,\n",
    "    StringLookup,\n",
    "    Bidirectional,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils import CustomNonPaddingTokenLoss\n",
    "from conlleval import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3215bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 22:54:52.744082: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-29 22:54:52.744113: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-29 22:54:52.744138: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (calcifer-Inspiron-7370): /proc/driver/nvidia/version does not exist\n",
      "2022-12-29 22:54:52.744591: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "(ds_dev, ds_train, ds_test), info = tfds.load(\n",
    "    name=\"conll2003\",\n",
    "    split=[\"dev\", \"train\", \"test\",],\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aafa22e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='conll2003',\n",
       "    full_name='conll2003/conll2022/1.0.0',\n",
       "    description=\"\"\"\n",
       "    The shared task of CoNLL-2003 concerns language-independent named entity\n",
       "    recognition and concentrates on four types of named entities: persons,\n",
       "    locations, organizations and names of miscellaneous entities that do not belong\n",
       "    to the previous three groups.\n",
       "    \"\"\",\n",
       "    homepage='https://www.aclweb.org/anthology/W03-0419/',\n",
       "    data_path='/home/calcifer/tensorflow_datasets/conll2003/conll2022/1.0.0',\n",
       "    file_format=tfrecord,\n",
       "    download_size=959.94 KiB,\n",
       "    dataset_size=3.87 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'chunks': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=23)),\n",
       "        'ner': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=9)),\n",
       "        'pos': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=47)),\n",
       "        'tokens': Sequence(Text(shape=(), dtype=tf.string)),\n",
       "    }),\n",
       "    supervised_keys=None,\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'dev': <SplitInfo num_examples=3251, num_shards=1>,\n",
       "        'test': <SplitInfo num_examples=3454, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=14042, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@inproceedings{tjong-kim-sang-de-meulder-2003-introduction,\n",
       "        title = \"Introduction to the {C}o{NLL}-2003 Shared Task: Language-Independent Named Entity Recognition\",\n",
       "        author = \"Tjong Kim Sang, Erik F.  and\n",
       "          De Meulder, Fien\",\n",
       "        booktitle = \"Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003\",\n",
       "        year = \"2003\",\n",
       "        url = \"https://www.aclweb.org/anthology/W03-0419\",\n",
       "        pages = \"142--147\",\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f9ccf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "tokens_train = ds_train.map(lambda r: r.get(\"tokens\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baeda1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ec9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    standardize=\"lower\",\n",
    "    split=None,\n",
    "    ragged=True,\n",
    "    # output_sequence_length=...,\n",
    ")\n",
    "\n",
    "vectorizer.adapt(tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63848df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_names: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n"
     ]
    }
   ],
   "source": [
    "label_names = info.features[\"ner\"].names\n",
    "print(\"label_names:\", label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad0439cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "MAX_SEQUENCE_LENGTH = 125\n",
    "\n",
    "ds_train_cld = (\n",
    "    ds_train\n",
    "    .map(lambda r: (vectorizer(r[\"tokens\"]), r[\"ner\"]+1))\n",
    "    .shuffle(buffer_size=100)\n",
    "    .padded_batch(batch_size=64, padded_shapes=([None], [None]))\n",
    ")\n",
    "ds_dev_cld = (\n",
    "    ds_dev\n",
    "    .map(lambda r: (vectorizer(r[\"tokens\"]), r[\"ner\"]+1))\n",
    "    .padded_batch(batch_size=64, padded_shapes=([None], [None]))\n",
    ")\n",
    "ds_test_cld = (\n",
    "    ds_test\n",
    "    .map(lambda r: (vectorizer(r[\"tokens\"]), r[\"ner\"]+1))\n",
    "    .padded_batch(batch_size=64, padded_shapes=([None], [None]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c52c35b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens shape: (64, 41)\n",
      "Tags shape: (64, 41)\n"
     ]
    }
   ],
   "source": [
    "for x in ds_dev_cld.take(1).as_numpy_iterator():\n",
    "    print(\"Tokens shape:\", x[0].shape)\n",
    "    print(\"Tags shape:\", x[1].shape)  # should be equal to tokens shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a88a35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ccbc496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tokens (InputLayer)         [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 128)         1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 256)        198144    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " tags (TimeDistributed)      (None, None, 10)          2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,480,714\n",
      "Trainable params: 1,480,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "inputs = Input(shape=(None,), name=\"tokens\")\n",
    "x = Embedding(\n",
    "    input_dim=VOCAB_SIZE,\n",
    "    output_dim=EMBEDDING_DIM,\n",
    "    mask_zero=True,\n",
    ")(inputs)\n",
    "x = Bidirectional(layer=GRU(\n",
    "    units=128,\n",
    "    dropout=0.2,\n",
    "    recurrent_dropout=0.2,\n",
    "    return_sequences=True,\n",
    "))(x)\n",
    "outputs = TimeDistributed(layer=Dense(units=len(label_names)+1, activation=\"softmax\"), name=\"tags\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d85d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=CustomNonPaddingTokenLoss(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc7d869d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "220/220 [==============================] - 28s 105ms/step - loss: 1.6737 - accuracy: 0.8280 - val_loss: 1.6287 - val_accuracy: 0.8329\n",
      "Epoch 2/25\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 1.6287 - accuracy: 0.8334 - val_loss: 1.6285 - val_accuracy: 0.8332\n",
      "Epoch 3/25\n",
      "220/220 [==============================] - 29s 130ms/step - loss: 1.6286 - accuracy: 0.8336 - val_loss: 1.6285 - val_accuracy: 0.8334\n",
      "Epoch 4/25\n",
      "220/220 [==============================] - 31s 141ms/step - loss: 1.6282 - accuracy: 0.8337 - val_loss: 1.6278 - val_accuracy: 0.8337\n",
      "Epoch 5/25\n",
      "220/220 [==============================] - 31s 141ms/step - loss: 1.6245 - accuracy: 0.8377 - val_loss: 1.6149 - val_accuracy: 0.8459\n",
      "Epoch 6/25\n",
      "220/220 [==============================] - 27s 123ms/step - loss: 1.5993 - accuracy: 0.8621 - val_loss: 1.5984 - val_accuracy: 0.8621\n",
      "Epoch 7/25\n",
      "220/220 [==============================] - 28s 126ms/step - loss: 1.5951 - accuracy: 0.8654 - val_loss: 1.5974 - val_accuracy: 0.8625\n",
      "Epoch 8/25\n",
      "220/220 [==============================] - 28s 129ms/step - loss: 1.5776 - accuracy: 0.8836 - val_loss: 1.5649 - val_accuracy: 0.8964\n",
      "Epoch 9/25\n",
      "220/220 [==============================] - 28s 128ms/step - loss: 1.5436 - accuracy: 0.9179 - val_loss: 1.5439 - val_accuracy: 0.9172\n",
      "Epoch 10/25\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 1.5130 - accuracy: 0.9493 - val_loss: 1.5253 - val_accuracy: 0.9360\n",
      "Epoch 11/25\n",
      "220/220 [==============================] - 27s 121ms/step - loss: 1.5045 - accuracy: 0.9571 - val_loss: 1.5239 - val_accuracy: 0.9369\n",
      "Epoch 12/25\n",
      "220/220 [==============================] - 27s 121ms/step - loss: 1.4983 - accuracy: 0.9635 - val_loss: 1.5144 - val_accuracy: 0.9470\n",
      "Epoch 13/25\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 1.4909 - accuracy: 0.9708 - val_loss: 1.5112 - val_accuracy: 0.9503\n",
      "Epoch 14/25\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 1.4872 - accuracy: 0.9745 - val_loss: 1.5093 - val_accuracy: 0.9521\n",
      "Epoch 15/25\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 1.4848 - accuracy: 0.9767 - val_loss: 1.5084 - val_accuracy: 0.9531\n",
      "Epoch 16/25\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 1.4833 - accuracy: 0.9783 - val_loss: 1.5082 - val_accuracy: 0.9529\n",
      "Epoch 17/25\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 1.4819 - accuracy: 0.9796 - val_loss: 1.5067 - val_accuracy: 0.9547\n",
      "Epoch 18/25\n",
      "220/220 [==============================] - 27s 122ms/step - loss: 1.4807 - accuracy: 0.9807 - val_loss: 1.5060 - val_accuracy: 0.9554\n",
      "Epoch 19/25\n",
      "220/220 [==============================] - 27s 122ms/step - loss: 1.4800 - accuracy: 0.9815 - val_loss: 1.5066 - val_accuracy: 0.9546\n",
      "Epoch 20/25\n",
      "220/220 [==============================] - 27s 122ms/step - loss: 1.4795 - accuracy: 0.9818 - val_loss: 1.5066 - val_accuracy: 0.9546\n",
      "Epoch 21/25\n",
      "220/220 [==============================] - 27s 123ms/step - loss: 1.4788 - accuracy: 0.9825 - val_loss: 1.5060 - val_accuracy: 0.9554\n",
      "Epoch 22/25\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 1.4785 - accuracy: 0.9830 - val_loss: 1.5067 - val_accuracy: 0.9541\n",
      "Epoch 23/25\n",
      "220/220 [==============================] - 26s 120ms/step - loss: 1.4778 - accuracy: 0.9835 - val_loss: 1.5058 - val_accuracy: 0.9554\n",
      "Epoch 24/25\n",
      "220/220 [==============================] - 27s 122ms/step - loss: 1.4774 - accuracy: 0.9840 - val_loss: 1.5059 - val_accuracy: 0.9553\n",
      "Epoch 25/25\n",
      "220/220 [==============================] - 26s 120ms/step - loss: 1.4771 - accuracy: 0.9842 - val_loss: 1.5051 - val_accuracy: 0.9562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd0ec16a590>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 25\n",
    "\n",
    "model.fit(\n",
    "    ds_train_cld,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=ds_dev_cld,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd4180d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 2s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "prob_preds_test = model.predict(ds_test_cld)\n",
    "preds_test = [np.argmax(x, axis=-1) for x in prob_preds_test.to_list()]\n",
    "\n",
    "labels_test = [r[1] for r in ds_test_cld.unbatch().as_numpy_iterator()]\n",
    "\n",
    "for idx in range(len(preds_test)):\n",
    "    assert preds_test[idx].shape == labels_test[idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d53579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_idx_concat, labels_idx_concat = list(), list()\n",
    "\n",
    "for (p, l) in zip(preds_dev, labels_dev):\n",
    "    mask = l > 0\n",
    "    preds_idx_concat += p[mask].tolist()\n",
    "    labels_idx_concat += l[mask].tolist()\n",
    "    \n",
    "preds_concat = [label_names[tag-1] for tag in preds_idx_concat]\n",
    "labels_concat = [label_names[tag-1] for tag in labels_idx_concat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b431deb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51362 tokens with 5942 phrases; found: 5347 phrases; correct: 4531.\n",
      "accuracy:  76.22%; (non-O)\n",
      "accuracy:  95.44%; precision:  84.74%; recall:  76.25%; FB1:  80.27\n",
      "              LOC: precision:  89.67%; recall:  82.25%; FB1:  85.80  1685\n",
      "             MISC: precision:  86.82%; recall:  70.72%; FB1:  77.94  751\n",
      "              ORG: precision:  74.65%; recall:  63.24%; FB1:  68.47  1136\n",
      "              PER: precision:  85.63%; recall:  82.52%; FB1:  84.05  1775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(84.73910604077052, 76.2537866038371, 80.27283196031534)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(labels_concat, preds_concat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
