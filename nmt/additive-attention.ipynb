{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4725d949-c6b0-4d46-b9ba-7f981de492d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 23:22:06.675253: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-05 23:22:06.870153: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-05 23:22:06.870192: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-05 23:22:07.997937: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-05 23:22:07.998003: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-05 23:22:07.998011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import einops\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import models as M\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from tensorflow_text import normalize_utf8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b52311c-3f7c-4035-a9c9-111cf913219f",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344dd867-1e85-46ed-8b56-a34a3f5a337c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 358373 entries, 0 to 358372\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   eng     358373 non-null  object\n",
      " 1   ita     358373 non-null  object\n",
      " 2   author  358373 non-null  object\n",
      " 3   split   358373 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 10.9+ MB\n"
     ]
    }
   ],
   "source": [
    "path_to_file = pathlib.Path().home() / \"tensorflow_datasets\" / \"anki\" / \"ita-eng\" / \"ita.txt\"\n",
    "df = pd.read_csv(path_to_file, sep=\"\\t\", header=None)\n",
    "df.columns=[\"eng\", \"ita\", \"author\"]\n",
    "df[\"split\"] = np.where(np.random.uniform(size=(len(df),)) < 0.8, \"train\", \"val\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb1d9af-6156-41a2-a696-2e41e47769c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>ita</th>\n",
       "      <th>author</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ciao!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ciao.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corri!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corra!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Correte!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eng       ita                                             author  split\n",
       "0   Hi.     Ciao!  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  train\n",
       "1   Hi.     Ciao.  CC-BY 2.0 (France) Attribution: tatoeba.org #5...    val\n",
       "2  Run!    Corri!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  train\n",
       "3  Run!    Corra!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...    val\n",
       "4  Run!  Correte!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  train"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fdafc7-fc68-4d76-999e-645ff3b00324",
   "metadata": {},
   "source": [
    "## Prep dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "06f88ba2-3adb-4224-b4b5-3f23d8d1cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d67532-c458-44bf-aed5-27ea5f04f203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 23:22:10.602214: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-05 23:22:10.602241: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-05 23:22:10.602264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (calcifer-Inspiron-7370): /proc/driver/nvidia/version does not exist\n",
      "2023-01-05 23:22:10.602564: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((\n",
    "        df.query(\"split == 'train'\")[\"ita\"].values,\n",
    "        df.query(\"split == 'train'\")[\"eng\"].values,\n",
    "    ))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "\n",
    "val_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((\n",
    "        df.query(\"split == 'val'\")[\"ita\"].values,\n",
    "        df.query(\"split == 'val'\")[\"eng\"].values,\n",
    "    ))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe6486a-c367-429a-9748-3051e301aef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def clean_string(s):\n",
    "    # Split accented characters\n",
    "    text = normalize_utf8(s, \"NFKD\")\n",
    "    text = tf.strings.lower(text)\n",
    "    # Keep space, a to z, and select punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,;]', '')\n",
    "    # Add spaces around punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[.?!,;]', r' \\0 ')\n",
    "    # Strip whitespace.\n",
    "    text = tf.strings.strip(text)\n",
    "    # Add START and END tokens\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b639ae9-7719-4292-bf7c-d4ec6cea6816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/calcifer/git/marco/learn-deep-learning/.env/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "vectorizer_src = L.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    standardize=clean_string,\n",
    "    ragged=True,\n",
    "    encoding='utf-8',\n",
    ")\n",
    "vectorizer_src.adapt(train_raw.map(lambda src, dst: src))\n",
    "\n",
    "vectorizer_dst = L.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    standardize=clean_string,\n",
    "    ragged=True,\n",
    "    encoding='utf-8',\n",
    ")\n",
    "\n",
    "vectorizer_dst.adapt(train_raw.map(lambda src, dst: dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d69425b3-8c1c-4209-a006-2bc2f8e3ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset(src, dst):\n",
    "    src_enc = vectorizer_src(src).to_tensor()\n",
    "    dst_enc = vectorizer_dst(dst)\n",
    "    dst_in = dst_enc[:, :-1].to_tensor()\n",
    "    dst_out = dst_enc[:, 1:].to_tensor()\n",
    "    return (src_enc, dst_in), dst_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a24daee-5103-49d8-8d41-8f99ccf349a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = train_raw.map(prep_dataset, tf.data.AUTOTUNE)\n",
    "ds_val = val_raw.map(prep_dataset, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb4b43-e387-40bc-be90-0111ad02988b",
   "metadata": {},
   "source": [
    "## Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "45dc30f9-0fca-40cf-a995-6e16f4bebef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 128\n",
    "RNN_UNITS = 32\n",
    "ATTENTION_UNITS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "4212642e-d2c5-45d0-bc01-7483daff91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_kwargs = dict(\n",
    "    dropout=0.2, \n",
    "    recurrent_dropout=0.2, \n",
    "    recurrent_initializer=\"glorot_uniform\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "d0904b66-6659-483e-8da4-39020b1bf0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeChecker():\n",
    "    def __init__(self):\n",
    "    # Keep a cache of every axis-name seen\n",
    "        self.shapes = {}\n",
    "\n",
    "    def __call__(self, tensor, names, broadcast=False):\n",
    "        if not tf.executing_eagerly():\n",
    "            return\n",
    "\n",
    "        parsed = einops.parse_shape(tensor, names)\n",
    "\n",
    "        for name, new_dim in parsed.items():\n",
    "            old_dim = self.shapes.get(name, None)\n",
    "\n",
    "            if (broadcast and new_dim == 1):\n",
    "                continue\n",
    "\n",
    "            if old_dim is None:\n",
    "                # If the axis name is new, add its length to the cache.\n",
    "                self.shapes[name] = new_dim\n",
    "                continue\n",
    "\n",
    "            if new_dim != old_dim:\n",
    "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                                 f\"    found: {new_dim}\\n\"\n",
    "                                 f\"    expected: {old_dim}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "ca17a6f9-fab8-4161-9d2a-3a827fc550da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(M.Model):\n",
    "    def __init__(self, rnn_units: int, vocab_size: int, embedding_dim: int):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = L.Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)\n",
    "        self.rnn = L.Bidirectional(\n",
    "            layer=L.GRU(units=rnn_units, return_sequences=True, **rnn_kwargs),\n",
    "            merge_mode=\"sum\",\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        outputs = self.rnn(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "9be83aec-f7da-4604-ad82-ebde2771b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveAttention(L.Layer):\n",
    "    def __init__(self, units: int):\n",
    "        super().__init__()\n",
    "        self.w1 = L.Dense(units=units, use_bias=False)\n",
    "        self.w2 = L.Dense(units=units, use_bias=False)\n",
    "        self.v = L.Dense(1, use_bias=False)\n",
    "\n",
    "    def call(self, query, keys):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(query, \"batch t_enc rnn_units\")\n",
    "        shape_checker(keys, \"batch t_dec emb_dec\")\n",
    "        # add nexaxis for broadcasting addition along the time dimensions\n",
    "        scores_query = tf.expand_dims(self.w1(query), axis=2)\n",
    "        scores_keys = tf.expand_dims(self.w2(keys), axis=1)\n",
    "        scores = self.v(tf.tanh(tf.add(scores_query, scores_keys)))\n",
    "        scores = tf.squeeze(scores)\n",
    "        shape_checker(scores, \"batch t_enc t_dec\")\n",
    "        attention_scores = tf.math.softmax(scores, axis=1)  # for each t_enc, unit sum\n",
    "        context = tf.matmul(attention_scores, keys)\n",
    "        return context, attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "3c613598-68cd-4cc2-a54d-ebbd8baad76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(M.Model):\n",
    "    def __init__(self, rnn_units: int, vocab_size: int, embedding_dim: int, attention_units: int):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = L.Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)\n",
    "        self.rnn = L.GRU(units=rnn_units, return_state=True, return_sequences=True, **rnn_kwargs)\n",
    "        self.attention = AdditiveAttention(units=attention_units)\n",
    "        self.out = L.Dense(units=vocab_size)\n",
    "        self.last_attention_scores = None\n",
    "    def call(self, inputs, enc_hidden_states, state=None, return_state: bool = False):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(inputs, \"batch t_dec\")\n",
    "        shape_checker(enc_hidden_states, \"batch t_enc rnn_units\")\n",
    "        #\n",
    "        emb = self.embedding(inputs)\n",
    "        shape_checker(emb, \"batch t_dec emb\")\n",
    "        #\n",
    "        rnn_out, rnn_state = self.rnn(emb, initial_state=state)\n",
    "        shape_checker(rnn_out, \"batch t_dec rnn_units\")\n",
    "        #\n",
    "        context, attention_scores = self.attention(rnn_out, enc_hidden_states)\n",
    "        self.last_attention_scores = attention_scores\n",
    "        shape_checker(context, \"batch t_dec rnn_units\")\n",
    "        logits = self.out(context)\n",
    "        shape_checker(logits, 'batch t_dec vocab_size')\n",
    "        out = (logits, state) if return_state else logits\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "9f331364-d963-4fd2-a9be-87befd7b1435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape_checker = ShapeChecker()\n",
    "enc_inputs, dec_inputs = ds_train.take(1).as_numpy_iterator().next()[0]\n",
    "shape_checker(enc_inputs, \"batch t_enc\")\n",
    "\n",
    "encoder = Encoder(rnn_units=RNN_UNITS, embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE)\n",
    "enc_outputs = encoder(enc_inputs)\n",
    "shape_checker(enc_outputs, \"batch t_enc rnn_units\")\n",
    "\n",
    "decoder = Decoder(rnn_units=RNN_UNITS, embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE, attention_units=16)\n",
    "logits = decoder(dec_inputs[:, :3], enc_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "f8f4a43b-c11e-44d4-8ae5-36cb9407b327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 3, 30000])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "ef7c04d7-21ce-4fee-a3c4-b0f8c592cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(M.Model):\n",
    "    def __init__(\n",
    "        self, \n",
    "        rnn_units: int = RNN_UNITS, \n",
    "        vocab_size: int = VOCAB_SIZE, \n",
    "        embedding_dim: int = EMBEDDING_DIM, \n",
    "        attention_units: int = ATTENTION_UNITS,\n",
    "    ):\n",
    "        super(Translator, self).__init__()\n",
    "        self.encoder = Encoder(rnn_units=rnn_units, embedding_dim=embedding_dim, vocab_size=vocab_size)\n",
    "        self.decoder = Decoder(rnn_units=rnn_units, embedding_dim=embedding_dim, vocab_size=vocab_size, attention_units=attention_units)\n",
    "    \n",
    "    def call(self, inputs_enc, inputs_dec):\n",
    "        enc_hidden_states = self.encoder(inputs_enc)\n",
    "        logits = self.decoder(inputs_dec, enc_hidden_states)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d89d4f-3498-429b-af52-61321ce033d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31187d5a-d26f-4004-8a36-be1775907186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0130307-7c8e-4c07-bfb8-f1107e33526c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a896c39c-bb6e-4c24-aaed-46dfcf26d010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7639767-5a94-48f2-a860-c42a47019620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109a3e4-e49b-47dd-8b87-974f57e1c76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b983f64f-efde-471d-bac4-f6b25db1f126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f25be5-1ec6-46c6-b3b1-6476a18bbf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45faf89b-39f5-40b5-b347-1baf73edeb27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773bc268-33c8-4a6e-80bc-a84e14f8e63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741ef53-ddf6-493f-8155-7e0ca342bd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8147c4-d7dc-415d-a882-72466c9b2672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f7f4c-6cfa-4bc1-a71d-7f96a4875feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6906169-2d8d-41a5-b6a1-cdaa301bbf49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda2e99c-bde3-4e81-aadb-7ba95d329800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b5455-32f2-45d0-a2e5-bec024fd61e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda1ba8-6424-4382-a371-1927f55bd5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f5628-71b8-400c-b327-7deded886c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b5f5a-1e21-4119-a57b-de58e11037b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189adde4-a0cd-4aa2-94bb-83224d4713f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f311587-f4e9-473b-bf99-671403d36bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d422c05-4c95-4141-a6a2-9c35a73e9608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c583f2-b2ff-4e2d-80ff-7463dcf8d5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47de614-d98d-440f-94e8-a7fc6d7e49a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089be299-3f15-4d9a-8bf1-001229c63ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391e85d-42c1-42a3-bc9d-867e64b08506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81083ec-205b-479f-8514-55bb77844527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54846fac-46af-4998-84e5-9ea2dc4a24a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "9fdf1802-3590-4744-b830-49bc21a2a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "c0898f0a-0789-4b2f-8d98-f02ac0dd39af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 6, 30000])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(enc_inputs, dec_inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1d8c101f-f653-4d83-824c-dcd1cb66b8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 8)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "28c04cd2-9796-4863-99d4-94bf6f155bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 8, 32])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "eb09cf6f-35ce-497a-9dc4-407609503e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_inputs[:, :3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "aff807b5-fb13-41fb-8ffa-a4826b951af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 3, 128])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_emb = decoder.embedding(dec_inputs[:, :3])\n",
    "decoder_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "99a81390-e029-4e6e-8874-1f7732ebb4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 3, 32)\n",
      "(64, 32)\n"
     ]
    }
   ],
   "source": [
    "dec_rnn_out, state = decoder.rnn(decoder_emb)\n",
    "print(dec_rnn_out.shape)\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c125e403-6518-4140-8f4b-25929acd5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = AdditiveAttention(units=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "2ab750ca-ac98-4020-8551-44b672a2ab27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 1, 8, 16])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_keys = tf.expand_dims(attention.w1(enc_outputs), axis=1)\n",
    "scores_keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "2408db45-574c-41f4-b0f9-f1b876d2f27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 3, 1, 16])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_values = tf.expand_dims(attention.w2(dec_rnn_out), axis=2)\n",
    "scores_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "0e38d6d8-46b4-4e2e-9db0-b438f7c7a981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 3, 8])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = attention.v(tf.tanh(tf.add(scores_keys, scores_values)))\n",
    "scores = tf.squeeze(scores)  # drop last dimension\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b41b3ad0-d854-48b2-97e3-cbb77cf0f708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 3, 8])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores = tf.math.softmax(scores, axis=-1)\n",
    "attention_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "84cb71e1-d408-4c26-b62c-88987c6f7b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 3, 32])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(attention_scores, enc_outputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3993c02-8e99-435c-9205-3ecefa651325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
